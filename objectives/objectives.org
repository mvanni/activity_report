* <2017-09-22 Fri>
** 1. TECHNICAL COMPETENCE
*** Acoustic Models for Low Resource Languages
**** Problem
ASR coponents like acousti models are not available for key low resource languages and accented versions of major languages.
**** Research Question
Can small and large resources  available from many languages be leveraged to build acoustic models for a language for which we have very few resources?
**** Proposed Method 
I will choose a target language  say Korean for which we actually have some resources so that we can evaluate results. 
I will use the kaldi multilang recipe to build acoustic models for  the target "low" resource language Korean given resources from many other source languages. 
I will obtain the source language resources from the GlobalPhone corpus and government owned corpora that are available to us (see below).
** Corpus Curation
*** Problem:
In my previous job, I was part of a team that developed speech corpora for the  following languages: 
1. Arabic (West Point LDC2002S02)
2. Arabic (Tunisia)
3. French (collected in Yaounde Cameroon)
4. Croatian (LDC2005S28)
5. German
6. Korean (LDC2006S36)
7. Portuguese (Brazilian LDC2008s04)
8. Russian (West Point LDC2003S05)
9. Russian (SOF Peter)
10. Spanish (Heroico LDC2006S37)

Of these 10 corpora, 6 were published in the Linguistic Data Consortium. 
The remaining 4 corpora for Arabic, French, German  and Russian are available to our team and have yet to be published. 
Unless the corpora are published, results obtained from training ASR systems with them are not reproduceable.

*** Proposed Method: 
I have 3 related goals this year concerning these 4 remaining corpora.
First, I want to prepare these corpora for use as source data in the project mentioned above. 
Second, I want to publish these corpora in the openslrm.org repository.
Third, In addition to the multilang project, I want to write Kaldi recipes  for each corpus. 

Publishing these corpora is an important goal. 
It is not hard to imagine these corpora disappearing after our generation retires. 

Preparing the data  and writing the recipes will entail producing a lexicon that I also would like to publlish on openslr.org.

* 2016-2017: 
** 1. TECHNICAL COMPETENCE
*** ASR Adaptation:
It is not clear that the advances made last year can be implemented in applications that would directly benefit the Army. 
This year I propose to capitalize on last year's successes by investigating ASR models that have well defined pathways to implementation  in speech to speech devices. 
I will focus on developing models that result in software that can be demoed with realtime interaction. 

*** kaldi:

The ASR systems I have built this year are based on HMMs and SGMMs. 
I will consider these systems as baselines for the work I will do using neural network models. 
I will continue developing with the Kaldi ASR toolkit. 
Specifically, I will implement systems with the following kaldi named models:
Bottle Neck Features
Chain Models
nnet2
nnet3
TDNNs
RBMs
Eesen end to end rnn and lstm models.

I will replicate for Arabic the work I did last year for French. 
That is, I will adapt Standard Arabic models to Tunisian accented speech in the same way I adapted European French to African accents.
I will make an effort to improve the language modeling component of the French and Arabic systems I develop with Kaldi.

*** Lexicon expansion
I will attempt to use the work done in the Babel project for automatic lexicon expansion in our African French and Tunisian Arabic corpora. 
This might involve automatic syllable boundary labeling. 

*** Afghan Languages 

I will build ASR systems for Dari and Pashto. 
I will leverage resources produced by the babel project for Pashto. 
I will work with Hazrat Ghulam Jahed on building high quality Dari and Pashto ASR systems.

*** Research:
**** Variable Structured computational graphs.
Many models used in NLP applications have a network of connected nodes. 
Training these networks has been restricted to computing weights associated with the connections. 
The topology of the networks has largely remained fixed. 
Lately there have been attempts to develop training methods that change the network topology with each training example. 
I propose to learn to use a toolkit called DyNet (or one like it) that is designed to build systems with variable graph structures. 

I plan on using DyNet or a toolkit similar to it to build a Machine Translation System and to compare its performance with systems built with other reference toolkits like Joshua, Moses, Tensorflow, etc.  
** 2. COOPERATION

Collaborate with colleagues to write papers that report on advances made in our projects. 
Collaborate with the Basic Research team by contributing speech recognition components to efforts such as the bot language project. 
** 3. COMMUNICATIONS

Write weekly activity reports to team members to keep them up to date on my work. 
Read and comment on reports made by my team and branch mates.

** 4. MGMT. OF TIME & RESOURCES

Set aside time during the day to practice some kind of  activity for physical fitness. 
Stay abreast of possible areas where hardware upgrades could improve work efficiency. 
** 5. CUSTOMER RELATIONS

Establish relationships with MFLTS and CERDEC to remain aware of Army requirements.
Establish contacts with researchers in the ASR and NLP fields. 
Establish contacts with s2s device manufacturers.

** 6. TECH TRANSITION

Contribute recipes for building ASR systems with our corpora to the MFLTS. 
Transition ASR components and our other products to USA Army Africa and MFLTS.  
** 7. DIVERSITY: 
Support ARL's diversity initiatives by participating in locally-sponsored diversity training, broad outreach, and/or special emphasis programs to increase personal awareness and understanding of the various cultures that exist among laboratory employees. 
** 8. SHARP: 
Support leadership's efforts to address and prevent sexual harassment and sexual assault and ensure a respectful work environment for all. 
Demonstrate support for the SHARP program by actively participating in required training and other educational programs. 
Intervene and appropriately respond to any instances of sexual harassment or sexual assault and encourage others to do the same.

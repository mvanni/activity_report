* Accomplishments <2017-08-31 Thu>

** The ULTRA Project
A goal set last year was  to investigate Automatic Speech Recognition (ASR) models that have well defined pathways to implementation  in speech to speech (S2S) devices. 
I pledged to  develop models that result in software that can be demoed with realtime interaction. 

I believe I achieved this goal and together with my ATeam colleagues we far exceeded our expectations of what could be done in this area. 
I was part of an effort by the Applications Team to develop a platform where the products we produce could be implemented and tested under conditions that would more closely resemble the actual conditions that Soldiers would face in the field. 
The ATeam made the necessary contacts with an industry contractor working for a  branch in the SED division to build a prototype S2S device on a smart phone that would be capable of running the software products we develop. 
The prototype system is currently called ULTRA.
A demo run on that prototype system used acoustic models and other components that I developed this year.
Although the future of this project is not certain, in the past year the ATeam went from  baseline systems that ran only on laboratory computers to having a functioning prototype running our own acoustic models and other software components on a smart phone. 

** African French:
I was part of an ATeam effort to coach the VoxTek team on adapting their existing English French S2S application to African Accented Speech. 
I developed African Accented French ASR components as a part of the VoxTek project and for the ULTRA project as well. 
To make sure I was getting state-of-the-art performance from the components I was building, I took on the task of replicating the results that were published in the Kaldi repository for the baseline GP French ASR system. 
Despite the fact that I did not have the exact same lexicon as the one that was used in the published results, my results were very close. 
I also produced better WER scores using chain models that were not available at the time the results were published. 
Specifically, the best published WER results are 22.51% with boosted maximum mutual information training while I obtained a 21.21% with chain models and 21.24 with online chain models.
It should be noted that the online chain models are designed to run in online or real time mode, whereas it is not clear that this can be accomplished with the sgmm models. 
The tri2b models that we have verified do work on the smart phone platform only achieved a 25.65% WER. 
I curated several small speech corpora for use as training data including African Accented French speech from Cameroon, Chad, Congo, Gabon and Niger. 
These corpora can be used later in experiments that measure the influence of Accent on ASR systems. 

** Publication of Heroico Recipe 
In the past year I have become familiar with the concept of a "recipe" in the context of the Kaldi ASR toolkit. 
I have written my own recipes for several languages including: Arabic, French, German, Russian and Spanish. 
It takes time to learn how to write concise recipe scripts. 
A major achievement this year is getting my recipe for the Heroico Spanish Corpus accepted in the Kaldi repository. 
My recipe is an example of what I have learned in the past year about building state-of-the-art ASR systems with Kaldi. 
First, I have scripts that perform the tedious but nonetheless important task of preparing the acoustic and text datain the Heroico corpus for processing by the Kaldi training and evaluation tools. 
I am especially proud of this work since I was involved in every aspect of the creation of the Heroico Corpus which is available from the LDC. 
After data preparation, I go through the standard Kaldi steps of progressively building context dependent (CD) gaussian mixture (GMM) hidden markov model (HMM) acoustic models. 
Then I haves scripts that use the CD GMM HMM models to train an I-Vector extractor. 
In the last training step, I train chain models which are the currently best performing neural network acoustic models. 
Chain models  are a kind of time delayed neural network (TDNN) that are trained on speed perturbed (SP) acoustic data. 
The I-Vector extraction and TDNN SP models are part of a third generation of neural networks that Kaldi calls nnet3. 
I mention TDNN SP and nnet3 because I had stated as a goal to investigate these kinds of models.
Finally, I have scripts that evaluate the performance of the systems at each step of the building process. 
Word Error Rates are generated for each of these steps. 
One kind of model I had mentioned in my goals that I did not get to are bottleneck neural networks. 
However, I have not ignored these kinds of models. 
In fact, recently most of my work has involved preparing for next year's project that will involve Bottlenect neural networks. 

I explored other neural network approaches for ASR in my work on the African Accented French. 
Among those approaches I will mention that I tried the rnn lstm models with the Eesen add on to Kaldi. 
The character-base version of this approach was fairly easy to implement since it does not use a lexicon. 
However, the results were not encouraging. 
The WER scores were in the mid forties while comparable scores for the cd gmm hmm approach were in the mid twenties. 
The rnn lstm approach might have advantages that are not apparent to me at the moment (perhaps online decoding), but I drop the exploration of this approach because of the bad performance. 

I also explored several other approaches including Deep Neural Network (DNN), Deep Belief Networks and Restricted Boltzmann Machines (RBMs). 
The WER scores for these approaches were good, but not quite as good as those for the CD GMM HMM approach. 
Since they also involved longer and more  complicated training regimes, I also dropped them and focused my attention on chain models. 

I had set as a goal  to replicate for Arabic the work I did last year for French. 
That is, I will adapt Standard Arabic models to Tunisian accented speech in the same way I adapted European French to African accents.


I will make an effort to improve the language modeling component of the French and Arabic systems I develop with Kaldi.



*** Lexicon expansion
I will attempt to use the work done in the Babel project for automatic lexicon expansion in our African French and Tunisian Arabic corpora. 
This might involve automatic syllable boundary labeling. 

*** Afghan Languages 

I will build ASR systems for Dari and Pashto. 
I will leverage resources produced by the babel project for Pashto. 
I will work with Hazrat Ghulam Jahed on building high quality Dari and Pashto ASR systems.

** Research:
*** Variable Structured computational graphs.
Many models used in NLP applications have a network of connected nodes. 
Training these networks has been restricted to computing weights associated with the connections. 
The topology of the networks has largely remained fixed. 
Lately there have been attempts to develop training methods that change the network topology with each training example. 
I propose to learn to use a toolkit called DyNet (or one like it) that is designed to build systems with variable graph structures. 

I plan on using DyNet or a toolkit similar to it to build a Machine Translation System and to compare its performance with systems built with other reference toolkits like Joshua, Moses, Tensorflow, etc.  
** 2. COOPERATION

Collaborate with colleagues to write papers that report on advances made in our projects. 
Collaborate with the Basic Research team by contributing speech recognition components to efforts such as the bot language project. 
** 3. COMMUNICATIONS
   
Write weekly activity reports to team members to keep them up to date on my work. 
Read and comment on reports made by my team and branch mates.

** 4. MGMT. OF TIME & RESOURCES

Set aside time during the day to practice some kind of  activity for physical fitness. 
Stay abreast of possible areas where hardware upgrades could improve work efficiency. 
** 5. CUSTOMER RELATIONS

Establish relationships with MFLTS and CERDEC to remain aware of Army requirements.
Establish contacts with researchers in the ASR and NLP fields. 
Establish contacts with s2s device manufacturers.

** 6. TECH TRANSITION

Contribute recipes for building ASR systems with our corpora to the MFLTS. 
Transition ASR components and our other products to USA Army Africa and MFLTS.  
** 7. DIVERSITY: 
Support ARL's diversity initiatives by participating in locally-sponsored diversity training, broad outreach, and/or special emphasis programs to increase personal awareness and understanding of the various cultures that exist among laboratory employees. 
** 8. SHARP: 
Support leadership's efforts to address and prevent sexual harassment and sexual assault and ensure a respectful work environment for all. 
Demonstrate support for the SHARP program by actively participating in required training and other educational programs. 
Intervene and appropriately respond to any instances of sexual harassment or sexual assault and encourage others to do the same.

* Accomplishments <2017-04-04 Tue>
- Extended minimal Tunisian ASR System to QCRI 2 million word arabic dictionary.
Used the Levenshtein distance to propose to a human expert pronunciations that are close to out of vocabulary words.
Converted buckwalter entries in QCRI dictionary to unicode utf8.
Prepared acoustic and text data for ASR model building with Kaldi on SOFTunis corpus.
- Attended IARPA Babel workshop on Kaldi and pyspeech.
Contributed improvement to Kaldi scripts used in IARPA workshop.
- Wrote scripts to Implement a multi-step process to perform semi-supervised training of acoustic models using unlabeled speech data from the Yaounde corpus.
Achieved improvements in WER score with semi-supervised training regime.
- Wrote scripts for processing all the African Accented French Data to  make an i-vector extractor for African Accented Speech.
- Wrote scripts for end to end  model training and testing with the Kaldi toolkit on several French corpora including:
globalPhone (GP)
GP + Yaounde African French ( chain model ) .
Gabon and Niger 2016 data collection. 
Models include:
Monophone (mono)
Triphones
Subspace Gaussian Mixture Models
- Prepared acoustic data and text labels for Yaounde African French and SOFTunis corpora.
- Setup training with eesen (recurrent neural network) toolkit on gp + Yaounde  corpus.
-Prepared data for lab test of VoxTek device.
- Pass Cyber security Fundamentals Course.
